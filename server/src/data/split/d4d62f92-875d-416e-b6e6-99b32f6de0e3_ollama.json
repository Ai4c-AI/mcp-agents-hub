{
  "mcpId": "github.com/rawveg/ollama-mcp",
  "githubUrl": "https://github.com/rawveg/ollama-mcp",
  "name": "Ollama",
  "author": "rawveg",
  "description": "Integrates Ollama's local LLM models with MCP-compatible applications, enabling on-premise AI processing and custom model deployment while maintaining data control.",
  "codiconIcon": "ollama",
  "logoUrl": "",
  "category": "developer-tools",
  "tags": [
    "ollama",
    "integrates",
    "ollama's",
    "enabling",
    "custom"
  ],
  "requiresApiKey": false,
  "isRecommended": false,
  "githubStars": 52,
  "downloadCount": 0,
  "createdAt": "2025-03-17T08:29:21.725369+00:00",
  "updatedAt": "2025-04-20T19:58:29Z",
  "hubId": "d4d62f92-875d-416e-b6e6-99b32f6de0e3",
  "isOfficialIntegration": false,
  "isReferenceServer": false,
  "isCommunityServer": true,
  "githubLatestCommit": "4d276b80e6c8da2faae5d8f2799ca81b54723680",
  "githubForks": 6,
  "licenseType": "AGPL-3.0"
}